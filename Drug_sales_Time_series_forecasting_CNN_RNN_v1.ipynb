{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EDAandModel_Drug_sales.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6822AEJ6CzID"
      },
      "source": [
        "import os\n",
        "import datetime\n",
        "\n",
        "import IPython\n",
        "import IPython.display\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import json\n",
        "from pandas import read_csv\n",
        "from datetime import datetime\n",
        "\n",
        "mpl.rcParams['figure.figsize'] = (8, 6)\n",
        "mpl.rcParams['axes.grid'] = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXFiozVLBK1v"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')#Just follow the link and login to your google account and get the authorization code and paste it where required."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcKN1YS7By0v"
      },
      "source": [
        "**Importing the library package, loading the dataset and reading the train_data **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wjPG5pVB250"
      },
      "source": [
        "##Exploratory data analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVUjJN5qB4Xt"
      },
      "source": [
        "# load data\n",
        "train_data = read_csv('/content/drive/MyDrive/PHD/train_data.csv',header = 0)\n",
        "train_data['year'] = (train_data['year']-2014)# to reduce the value in order to start preparing data for model\n",
        "train_data['month'] = (train_data['month'])\n",
        "train_data['day'] = (train_data['day'])\n",
        "train_data['city'] = train_data['city']\n",
        "\n",
        "# load dataset\n",
        "train_values = train_data.values\n",
        "# specify columns to plot\n",
        "groups = [0, 1, 2, 3, 4, 5]\n",
        "i = 1\n",
        "# plot each column\n",
        "plt.figure()\n",
        "for group in groups:\n",
        "\tplt.subplot(len(groups), 1, i)\n",
        "\tplt.plot(train_values[:, group])\n",
        "\tplt.title(train_data.columns[group], y=0.5, loc='right')\n",
        "\ti += 1\n",
        "plt.show()\n",
        "\n",
        "corr_coefs = train_data.corr()\n",
        "print(\"--------Wholesome Correlation matrix---------\")\n",
        "print(corr_coefs)\n",
        "\n",
        "corr_coefs1 = train_data[train_data['year']==1].corr()\n",
        "print(\"--------2015 Correlation matrix---------\")\n",
        "print(corr_coefs1)\n",
        "\n",
        "corr_coefs2 = train_data[train_data['year']==2].corr()\n",
        "print(\"--------2016 Correlation matrix---------\")\n",
        "print(corr_coefs2)\n",
        "\n",
        "corr_coefs3 = train_data[train_data['year']==3].corr()\n",
        "print(\"--------2017 Correlation matrix---------\")\n",
        "print(corr_coefs3)\n",
        "\n",
        "corr_coefs4 = train_data[train_data['year']==4].corr()\n",
        "print(\"--------2018 Correlation matrix---------\")\n",
        "print(corr_coefs4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oehZwCe8CDEW"
      },
      "source": [
        "  **To avoid warning messages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DilSttwWCHI1"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('always')\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfCo2q4PCYHl"
      },
      "source": [
        "def reduce_mem_usage(train_data):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    start_mem = train_data.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "    \n",
        "    for col in train_data.columns:\n",
        "        col_type = train_data[col].dtype\n",
        "        \n",
        "        if col_type != object:\n",
        "            c_min = train_data[col].min()\n",
        "            c_max = train_data[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    train_data[col] = train_data[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    train_data[col] = train_data[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    train_data[col] = train_data[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    train_data[col] = train_data[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    train_data[col] = train_data[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    train_data[col] = train_data[col].astype(np.float32)\n",
        "                else:\n",
        "                    train_data[col] = train_data[col].astype(np.float64)\n",
        "        else:\n",
        "            train_data[col] = train_data[col].astype('category')\n",
        "\n",
        "    end_mem = train_data.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "    \n",
        "    return train_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2bceHn4T-hf"
      },
      "source": [
        "pd.plotting.scatter_matrix(train_data, alpha=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzxlXpuVUOCi"
      },
      "source": [
        "**Next step would be to explore how the sales changed with day, month, year and city.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lxv9I8tuUSl0"
      },
      "source": [
        "#Data Visualization and Insights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPFpHvXEUIwE"
      },
      "source": [
        "#Plotting how sales changed with year,month, day.\n",
        "train_data.plot(x = 'year',y = 'sales')\n",
        "plt.figure()\n",
        "train_data.plot(x = 'month',y = 'sales')\n",
        "plt.figure()\n",
        "train_data.plot(x = 'day',y = 'sales')\n",
        "plt.figure()\n",
        "train_data.plot(x='medicine', y = 'sales')\n",
        "plt.figure()\n",
        "train_data.plot(x = 'city',y = 'sales')\n",
        "plt.figure()\n",
        "with open('/content/drive/MyDrive/PHD/city_dict.json') as f:\n",
        "    city_data = json.load(f)\n",
        "print(city_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6yFK8QoUkMd"
      },
      "source": [
        "Delhi (code 5) was found to be the highest selling place among all the city data present. Least selling was from other cities. Second least was Kolkata, which was a bit surprising. Because in terms of population there is not as much population difference between Kolkata and Delhi as that of Kolkata and Ahmedabad. However in the plot ahmedabad showed much higher sales than Kolkata and other cities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2-R8yXwUnYk"
      },
      "source": [
        "The correlation matrix shows that sles did not follow same pattern of change every year. From 2015-2017 amount of medicines in the store showed highest magnitude of correlation. however in 2018 city affected more than other factors, where amount of medicines in the store affected the least. However we don't have the data for approx. 5 months.\n",
        "\n",
        "  From previous comparison it can be said that the data doesn't follow linear relation. Hence ML model which is used later doesn't perform well in terms of RMSE. However when the data is trained using only the data from 2017-2018 only, the performance was found to be better. This suggests that concentrating on 6-8 months of data would be more useful i prediction rather than the data from 3 years."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEzL6ealUeP_"
      },
      "source": [
        "plt.hist2d(train_data['year'], train_data['sales'], bins=(50, 50), vmax=2000)\n",
        "plt.colorbar()\n",
        "plt.xlabel('year')\n",
        "plt.ylabel('sales')\n",
        "\n",
        "plt.figure()\n",
        "plt.hist2d(train_data['month'], train_data['sales'], bins=(50, 50), vmax=2000)\n",
        "plt.colorbar()\n",
        "plt.xlabel('month')\n",
        "plt.ylabel('sales')\n",
        "\n",
        "plt.figure()\n",
        "plt.hist2d(train_data['day'], train_data['sales'], bins=(50, 50), vmax=2000)\n",
        "plt.colorbar()\n",
        "plt.xlabel('day')\n",
        "plt.ylabel('sales')\n",
        "\n",
        "plt.figure()\n",
        "plt.hist2d(train_data['medicine'], train_data['sales'], bins=(50, 50), vmax=2000)\n",
        "plt.colorbar()\n",
        "plt.xlabel('medicine')\n",
        "plt.ylabel('sales')\n",
        "\n",
        "plt.figure()\n",
        "plt.hist2d(train_data['city'], train_data['sales'], bins=(50, 50), vmax=2000)\n",
        "plt.colorbar()\n",
        "plt.xlabel('city')\n",
        "plt.ylabel('sales')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WX-CL1moUw3s"
      },
      "source": [
        "**The time-frequency plot between each feature and sales would show the frequency at which they affect the sales. As expected for year as the data is for 2015, 2016, 2017 and 2018, hence at those instances the color is warmer than anywhere else in the plot. Similarly for months, as months are from 1-12, the color is warmer in those regions. The time-frequency plot between medicine and sales shows that storage of medicine less than approximately 2500 doesn't affect the sales to some extent when compared visually.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdmhGXV-aqHR"
      },
      "source": [
        "sns.pairplot(train_data)#This scatter plot matrix shows the relationship between different parameters."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LA3NIJwcMZP"
      },
      "source": [
        "**Read discount_features csv file,concatenate discount_data with train_data. Discount should be added in the training dataset to be more effective in changing strategy for sales.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i62VzrcZcLKS"
      },
      "source": [
        "discount_data = read_csv('/content/drive/MyDrive/PHD/discount_features.csv',header = 0)\n",
        "discount_data.head(5)\n",
        "discount_data['date'] = pd.to_datetime(discount_data['date'])\n",
        "discount_data['date']\n",
        "print(discount_data.head(5))\n",
        "discount_data.describe().transpose()\n",
        "data_merge = pd.concat([train_data, discount_data], ignore_index=True, sort=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkvglAdfcbU1"
      },
      "source": [
        "from scipy.stats import ttest_ind\n",
        "print(data_merge.head(5))\n",
        "corr_coefs_all = train_data.corr()\n",
        "print(\"--------Correlation matrix including discount data---------\")\n",
        "print(corr_coefs_all)\n",
        "print(\" \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geuKdQ1Tc2rG"
      },
      "source": [
        "**To check format of the date since code doesn't take object datatype**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCUnG0Zgc0x3"
      },
      "source": [
        "footfall_data = pd.read_csv(\"/content/drive/MyDrive/PHD/foot_fall.csv\")\n",
        "footfall_data.head(5)\n",
        "footfall_data=footfall_data.melt(id_vars=[\"city\"], \n",
        "        var_name=\"Date\", \n",
        "        value_name=\"Value\") \n",
        "footfall_data.head(10)\n",
        "city_names = pd.DataFrame.from_dict(city_data, orient=\"index\")\n",
        "city_names = city_names.reset_index()\n",
        "city_names.head(5)\n",
        "footfall_data['Date'] = pd.to_datetime(footfall_data['Date'])\n",
        "footfall_data['Date']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AS_lATi_dOKe"
      },
      "source": [
        "**These visualizations shows that number of customers in all the years did not vary much from each other , value of customer i,e footfall**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkIhssEndUrB"
      },
      "source": [
        "**Data Visualization and Insights**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKtAy1tcdZUk"
      },
      "source": [
        "footfall_data['year'] = footfall_data['Date'].dt.year\n",
        "footfall_data['month'] = footfall_data['Date'].dt.month\n",
        "footfall_data['day'] = footfall_data['Date'].dt.day\n",
        "footfall_data.head(5)\n",
        "\n",
        "import seaborn as sns\n",
        "#Plotting how sales changed with year.\n",
        "footfall_data.plot(x = 'year',y = 'Value')\n",
        "plt.figure()\n",
        "footfall_data.plot(x = 'month',y = 'Value')\n",
        "plt.figure()\n",
        "footfall_data.plot(x = 'day',y = 'Value')\n",
        "plt.figure()\n",
        "footfall_data.plot(x = 'city',y = 'Value')\n",
        "plt.figure()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTuY3MEwdgfK"
      },
      "source": [
        "**Variation in different features  present in train field, hence it was necessary to further look at frequency plot. Sales plot does not show clear relationship with other parameters hence studying the frequency domain was necessary, the relationship also reflected upon correlation between parameters which is very low**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-O02prGdp7H"
      },
      "source": [
        "plot_cols = ['year', 'month', 'day', 'city','medicine','sales']\n",
        "plot_features = train_data[plot_cols]\n",
        "_ = plot_features.plot(subplots=True)\n",
        "\n",
        "plot_features = train_data[plot_cols][:480]\n",
        "_ = plot_features.plot(subplots=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RHNWYLBd0fR"
      },
      "source": [
        "##Feature Engineering:\n",
        "**(1.) Here we would look at how the frequency \n",
        "affects the sales, year or day didn't show any high peaks at year , month and day frequency which tells sales was less influenced by frequency/periodicity.\n",
        "(2.)This plot shows that year frequency or day frequency did not show very clear stand-out feature which means that these two don't have so much effect on sales.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CszvAvIHeCFi"
      },
      "source": [
        "fft = tf.signal.rfft(train_data['sales'])\n",
        "f_per_dataset = np.arange(0, len(fft))\n",
        "\n",
        "n_samples_h = len(train_data['sales'])\n",
        "days_per_year = 365.2524\n",
        "days_per_month = 365.2524/12\n",
        "years_per_dataset = n_samples_h/(days_per_year)\n",
        "\n",
        "f_per_year = f_per_dataset/years_per_dataset\n",
        "plt.step(f_per_year, np.abs(fft))\n",
        "plt.xscale('log')\n",
        "plt.ylim(0, 100000)\n",
        "plt.xlim([0.1, max(plt.xlim())])\n",
        "plt.xticks([1, 365.2524/12, 365.2524], labels=['1/Year', '1/month', '1/day'])\n",
        "_ = plt.xlabel('Frequency (log scale)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LG6jCQ68fXA8"
      },
      "source": [
        "**Looking at the results, it can be said that it is important to look into why there is high variation in sales among biggest cities. It would be important to look into holidays and day of the week data to explore which days are the key days to change the amount of sales** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIU8FnHSCU75"
      },
      "source": [
        "**Reduce Memory Footprint Pandas**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJ-5I1V7Ctu-"
      },
      "source": [
        "import matplotlib as mpl\n",
        "mpl.rcParams['agg.path.chunksize'] = 10000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88nL0rvPCSaK"
      },
      "source": [
        "#load data\n",
        "csv_path = '/content/drive/MyDrive/PHD/train_data.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmDG9eNrf6Nh"
      },
      "source": [
        "##Machine Learning model Building\n",
        "\n",
        "\n",
        "1.   Data Preparation for effective model preparation.\n",
        "2.   Baseline Model preparation.\n",
        "3.   Find the best model and windowing method for this purpose.\n",
        "4.   Use the model to predict the sales for test.csv.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dS2NMhaBf33S"
      },
      "source": [
        "df = pd.read_csv(csv_path)\n",
        "# slice [start:stop:step], starting from left index every right indexth record.\n",
        "df = df[1::200] # THis sentence is in case you want to not take the whole data or read data over a period.\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jzb_V3gyj7OO"
      },
      "source": [
        "print(df.head())\n",
        "\n",
        "df['sales'] = df['sales'].clip(upper=2500) \n",
        "# In the training set there are some outliers which may reduce the performance of the model, because outliers meaning is not usual case. \n",
        "#Hence the data is slipped above 2500 for this dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pgms7G2bkY4v"
      },
      "source": [
        "**Splitting Data into training, validation and test dataset at 70:20:10 ratio of the total training data.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8w1MSAWvkcas"
      },
      "source": [
        "column_indices = {name: i for i, name in enumerate(df.columns)}\n",
        "\n",
        "n = len(df)\n",
        "train_df = df[0:int(n*0.7)]\n",
        "val_df = df[int(n*0.7):int(n*0.9)]\n",
        "test_df = df[int(n*0.9):]\n",
        "\n",
        "num_features = df.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gz9kfgrpkkxH"
      },
      "source": [
        "#Normalization of splitted datasets.\n",
        "  **The year values are in thousands whereas month varies from 1-12 while day varies from 1-31 and medicine from zero to thousands. High variation in the dataset may cause the model to not converge. Hence Normalization was needed.\n",
        "  There are many ways of normalizing the data. One is to subtract DC offset from the data and dividing standard deviation of whole training Dataset. However as year value contains only 4 unique values and in test dataset only single type of year value would be there, in that case this method can cause the year values to be Nans. \n",
        "  As Normalization meaning is to scale the data between certain limit, generally 0-1, dividing maximum would achieve the same.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAY1qGrBkxBQ"
      },
      "source": [
        "train_mean = train_df.mean()\n",
        "train_std = train_df.std()\n",
        "\n",
        "train_df = (train_df) / train_df.max()\n",
        "val_df = (val_df) / train_df.max()\n",
        "test_df = (test_df) / train_df.max()\n",
        "\n",
        "#train_df = (train_df - train_mean) / train_std\n",
        "#val_df = (val_df - train_mean) / train_std\n",
        "#test_df = (test_df - train_mean) / train_std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeohgdW3k1YC"
      },
      "source": [
        "**In time-series forecasting windowing is important to make predictions based on consecutive pair of features and labels. Different performance of model can be achieved based on the length of window and model used. Hence we are going to use different varieties of windows (wide, narrow, signle-step and multi-step).**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AseS89rWk7fr"
      },
      "source": [
        "class WindowGenerator():\n",
        "  def __init__(self, input_width, label_width, shift,\n",
        "               train_df=train_df, val_df=val_df, test_df=test_df,\n",
        "               label_columns=None):\n",
        "    self.train_df = train_df\n",
        "    self.val_df = val_df\n",
        "    self.test_df = test_df\n",
        "\n",
        "    self.label_columns = label_columns\n",
        "    if label_columns is not None:\n",
        "      self.label_columns_indices = {name: i for i, name in\n",
        "                                    enumerate(label_columns)}\n",
        "    self.column_indices = {name: i for i, name in\n",
        "                           enumerate(train_df.columns)}\n",
        "\n",
        "    # Set the window parameters.\n",
        "    self.input_width = input_width\n",
        "    self.label_width = label_width\n",
        "    self.shift = shift\n",
        "\n",
        "    self.total_window_size = input_width + shift\n",
        "\n",
        "    self.input_slice = slice(0, input_width)\n",
        "    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
        "\n",
        "    self.label_start = self.total_window_size - self.label_width\n",
        "    self.labels_slice = slice(self.label_start, None)\n",
        "    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
        "\n",
        "  def __repr__(self):\n",
        "    return '\\n'.join([\n",
        "        f'Total window size: {self.total_window_size}',\n",
        "        f'Input indices: {self.input_indices}',\n",
        "        f'Label indices: {self.label_indices}',\n",
        "        f'Label column name(s): {self.label_columns}'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpbmJMhek_AO"
      },
      "source": [
        "w1 = WindowGenerator(input_width=31, label_width=1, shift=1,\n",
        "                     label_columns=['sales'])\n",
        "w1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1piTQNSlAiY"
      },
      "source": [
        "w2 = WindowGenerator(input_width=10, label_width=1, shift=1,\n",
        "                     label_columns=['sales'])\n",
        "w2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVtroBTWlFSe"
      },
      "source": [
        "def split_window(self, features):\n",
        "  inputs = features[:, self.input_slice, :]\n",
        "  labels = features[:, self.labels_slice, :]\n",
        "  if self.label_columns is not None:\n",
        "    labels = tf.stack(\n",
        "        [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
        "        axis=-1)\n",
        "\n",
        "  # Slicing doesn't preserve static shape information, so set the shapes\n",
        "  # manually which makes it easier to make the dataset.\n",
        "  inputs.set_shape([None, self.input_width, None])\n",
        "  labels.set_shape([None, self.label_width, None])\n",
        "\n",
        "  return inputs, labels\n",
        "\n",
        "WindowGenerator.split_window = split_window"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAiFgW5blKTw"
      },
      "source": [
        "\n",
        "# Stack three slices, the length of the total window:\n",
        "example_window = tf.stack([np.array(train_df[:w2.total_window_size]),\n",
        "                           np.array(train_df[100:100+w2.total_window_size]),\n",
        "                           np.array(train_df[200:200+w2.total_window_size])])\n",
        "\n",
        "\n",
        "example_inputs, example_labels = w2.split_window(example_window)\n",
        "\n",
        "print('All shapes are: (batch, time, features)')\n",
        "print(f'Window shape: {example_window.shape}')\n",
        "print(f'Inputs shape: {example_inputs.shape}')\n",
        "print(f'labels shape: {example_labels.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zCB9qjAlOcl"
      },
      "source": [
        "w2.example = example_inputs, example_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0Zv4nD6lQuA"
      },
      "source": [
        "def plot(self, model=None, plot_col='sales', max_subplots=3):\n",
        "  inputs, labels = self.example\n",
        "  plt.figure(figsize=(12, 8))\n",
        "  plot_col_index = self.column_indices[plot_col]\n",
        "  max_n = min(max_subplots, len(inputs))\n",
        "  for n in range(max_n):\n",
        "    plt.subplot(3, 1, n+1)\n",
        "    plt.ylabel(f'{plot_col} [normed]')\n",
        "    plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n",
        "             label='Inputs', marker='.', zorder=-10)\n",
        "\n",
        "    if self.label_columns:\n",
        "      label_col_index = self.label_columns_indices.get(plot_col, None)\n",
        "    else:\n",
        "      label_col_index = plot_col_index\n",
        "\n",
        "    if label_col_index is None:\n",
        "      continue\n",
        "\n",
        "    plt.scatter(self.label_indices, labels[n, :, label_col_index],\n",
        "                edgecolors='k', label='Labels', c='#2ca02c', s=64)\n",
        "    if model is not None:\n",
        "      predictions = model(inputs)\n",
        "      plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n",
        "                  marker='*', edgecolors='k', label='Predictions',\n",
        "                  c='#ff7f0e', s=64)\n",
        "\n",
        "    if n == 0:\n",
        "      plt.legend()\n",
        "\n",
        "  plt.xlabel('days')\n",
        "\n",
        "WindowGenerator.plot = plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7E4C6ZvlUA8"
      },
      "source": [
        "w2.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SjcxVpAlY0h"
      },
      "source": [
        "**Built a dataset from the windows generated through make_dataset function.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p48ITdAkleKW"
      },
      "source": [
        "def make_dataset(self, data):\n",
        "  data = np.array(data, dtype=np.float32)\n",
        "  ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
        "      data=data,\n",
        "      targets=None,\n",
        "      sequence_length=self.total_window_size,\n",
        "      sequence_stride=1,\n",
        "      shuffle=True,\n",
        "      batch_size=30)\n",
        "\n",
        "  ds = ds.map(self.split_window)\n",
        "\n",
        "  return ds\n",
        "\n",
        "WindowGenerator.make_dataset = make_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pj9S8hzlixx"
      },
      "source": [
        "@property\n",
        "def train(self):\n",
        "  return self.make_dataset(self.train_df)\n",
        "\n",
        "@property\n",
        "def val(self):\n",
        "  return self.make_dataset(self.val_df)\n",
        "\n",
        "@property\n",
        "def test(self):\n",
        "  return self.make_dataset(self.test_df)\n",
        "\n",
        "@property\n",
        "def example(self):\n",
        "  result = getattr(self, '_example', None)\n",
        "  if result is None:\n",
        "    # No example batch was found, so get one from the `.train` dataset\n",
        "    result = next(iter(self.train))\n",
        "    # And cache it for next time\n",
        "    self._example = result\n",
        "  return result\n",
        "\n",
        "WindowGenerator.train = train\n",
        "WindowGenerator.val = val\n",
        "WindowGenerator.test = test\n",
        "WindowGenerator.example = example"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQ_1g6dqlmSI"
      },
      "source": [
        "# Each element is an (inputs, label) pair\n",
        "w2.train.element_spec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6o9PIFg7lov1"
      },
      "source": [
        "MAX_EPOCHS = 2\n",
        "\n",
        "def compile_and_fit(model, window, patience=2):\n",
        "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                                    patience=patience,\n",
        "                                                    mode='min')\n",
        "\n",
        "  model.compile(loss=tf.losses.MeanSquaredError(),\n",
        "                optimizer=tf.optimizers.Adam(),\n",
        "                metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "  history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
        "                      validation_data=window.val,\n",
        "                      callbacks=[early_stopping])\n",
        "  return history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sDInDkEltRK"
      },
      "source": [
        "#Baseline Model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gn9FCRi-lwP1"
      },
      "source": [
        "class Baseline(tf.keras.Model):\n",
        "  def __init__(self, label_index=None):\n",
        "    super().__init__()\n",
        "    self.label_index = label_index\n",
        "\n",
        "  def call(self, inputs):\n",
        "    if self.label_index is None:\n",
        "      return inputs\n",
        "    result = inputs[:, :, self.label_index]\n",
        "    return result[:, :, tf.newaxis]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30rYp_IAl0cT"
      },
      "source": [
        "#Baseline model using single step window: The model made to predict immediate short length based on current data.\n",
        "#Baseline model is necessary to test the performance of the base model i.e., simplest model to improve further and compare other models w.r.t the baseline model. Accordingly whichever model performs the best, would be selected to be used with the test.csv data. \n",
        "Use of linear model applies linear transform between input and output. Below implemented is one of the linear model implemented.\n",
        "\n",
        "Evaluation of the performance of the model based on the metrics set in the model.compile was conducted above and shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0P72ctol-mz"
      },
      "source": [
        "single_step_window = WindowGenerator(\n",
        "    # `WindowGenerator` returns all features as labels if you \n",
        "    # don't set the `label_columns` argument.\n",
        "    input_width=1, label_width=1, shift=1)\n",
        "\n",
        "wide_window = WindowGenerator(\n",
        "    input_width=31, label_width=31, shift=1)\n",
        "\n",
        "for example_inputs, example_labels in wide_window.train.take(1):\n",
        "  print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
        "  print(f'Labels shape (batch, time, features): {example_labels.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jx7F9YTJmAdC"
      },
      "source": [
        "baseline = Baseline()\n",
        "baseline.compile(loss=tf.losses.MeanSquaredError(),\n",
        "                 metrics=[tf.keras.metrics.RootMeanSquaredError()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IY-p-Fd-mCpH"
      },
      "source": [
        "#Dense model. In this model change in number of units can change the performance of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ms2jXLefmF06"
      },
      "source": [
        "dense = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=num_features)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKqkl8CDmHyV"
      },
      "source": [
        "history = compile_and_fit(dense, single_step_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "\n",
        "val_performance = {}\n",
        "performance = {}\n",
        "\n",
        "val_performance['Dense'] = dense.evaluate(single_step_window.val)\n",
        "performance['Dense'] = dense.evaluate(single_step_window.test, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xn8AT4AsmLOJ"
      },
      "source": [
        "class ResidualWrapper(tf.keras.Model):\n",
        "  def __init__(self, model):\n",
        "    super().__init__()\n",
        "    self.model = model\n",
        "\n",
        "  def call(self, inputs, *args, **kwargs):\n",
        "    delta = self.model(inputs, *args, **kwargs)\n",
        "\n",
        "    # The prediction for each timestep is the input\n",
        "    # from the previous time step plus the delta\n",
        "    # calculated by the model.\n",
        "    return inputs + delta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxRGR7aUmPZ2"
      },
      "source": [
        "%%time\n",
        "wide_window = WindowGenerator(\n",
        "    input_width=31, label_width=31, shift=1)\n",
        "\n",
        "lstm_model = tf.keras.models.Sequential([\n",
        "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
        "    tf.keras.layers.LSTM(64, return_sequences=True),\n",
        "    # Shape => [batch, time, features]\n",
        "    tf.keras.layers.Dense(units=num_features)\n",
        "])\n",
        "\n",
        "history = compile_and_fit(lstm_model, wide_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "val_performance['LSTM'] = lstm_model.evaluate( wide_window.val)\n",
        "performance['LSTM'] = lstm_model.evaluate( wide_window.test, verbose=0)\n",
        "\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAYyMiCDmX5A"
      },
      "source": [
        "%%time\n",
        "residual_lstm = ResidualWrapper(\n",
        "    tf.keras.Sequential([\n",
        "    tf.keras.layers.LSTM(64, return_sequences=True),\n",
        "    tf.keras.layers.Dense(\n",
        "        num_features,\n",
        "        # The predicted deltas should start small\n",
        "        # So initialize the output layer with zeros\n",
        "        kernel_initializer=tf.initializers.zeros)\n",
        "]))\n",
        "\n",
        "history = compile_and_fit(residual_lstm, wide_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "val_performance['Residual LSTM'] = residual_lstm.evaluate(wide_window.val)\n",
        "performance['Residual LSTM'] = residual_lstm.evaluate(wide_window.test, verbose=0)\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8HDMLpDmcoi"
      },
      "source": [
        "x = np.arange(len(performance))\n",
        "width = 0.3\n",
        "\n",
        "metric_name = 'root_mean_squared_error'\n",
        "metric_index = lstm_model.metrics_names.index('root_mean_squared_error')\n",
        "val_rmse = [v[metric_index] for v in val_performance.values()]\n",
        "test_rmse = [v[metric_index] for v in performance.values()]\n",
        "\n",
        "plt.bar(x - 0.17, val_rmse, width, label='Validation')\n",
        "plt.bar(x + 0.17, test_rmse, width, label='Test')\n",
        "plt.xticks(ticks=x, labels=performance.keys(),\n",
        "           rotation=45)\n",
        "plt.ylabel('RMSE (average over all outputs)')\n",
        "_ = plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78w8Ku_YmfyC"
      },
      "source": [
        "**This shows that Residual LSTM performed better than LSTM. However the RMSE was not very different between Dense and Residual LSTM.** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkPP8hAEmk4P"
      },
      "source": [
        "for name, value in performance.items():\n",
        "  print(f'{name:15s}: {value[1]:0.4f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aF8PTvibmnaR"
      },
      "source": [
        "OUT_STEPS = 31\n",
        "multi_window = WindowGenerator(input_width=31,\n",
        "                               label_width=OUT_STEPS,\n",
        "                               shift=OUT_STEPS)\n",
        "\n",
        "multi_window.plot()\n",
        "multi_window"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwitldNLmrCb"
      },
      "source": [
        "##Multistep Last Baseline:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkNCtesRmuQE"
      },
      "source": [
        "class MultiStepLastBaseline(tf.keras.Model):\n",
        "  def call(self, inputs):\n",
        "    return tf.tile(inputs[:, -1:, :], [1, OUT_STEPS, 1])\n",
        "\n",
        "last_baseline = MultiStepLastBaseline()\n",
        "last_baseline.compile(loss=tf.losses.MeanSquaredError(),\n",
        "                      metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "multi_val_performance = {}\n",
        "multi_performance = {}\n",
        "\n",
        "multi_val_performance['Last'] = last_baseline.evaluate(multi_window.val)\n",
        "multi_performance['Last'] = last_baseline.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(last_baseline)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTAWYF0PmyRW"
      },
      "source": [
        "class RepeatBaseline(tf.keras.Model):\n",
        "  def call(self, inputs):\n",
        "    return inputs\n",
        "\n",
        "repeat_baseline = RepeatBaseline()\n",
        "repeat_baseline.compile(loss=tf.losses.MeanSquaredError(),\n",
        "                        metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "multi_val_performance['Repeat'] = repeat_baseline.evaluate(multi_window.val)\n",
        "multi_performance['Repeat'] = repeat_baseline.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(repeat_baseline)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMr8hbvqm1pk"
      },
      "source": [
        "**Repeat baseline clearly shows better prediction than that of the previous two baselines.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3X3km4vXm38h"
      },
      "source": [
        "multi_linear_model = tf.keras.Sequential([\n",
        "    # Take the last time-step.\n",
        "    # Shape [batch, time, features] => [batch, 1, features]\n",
        "    tf.keras.layers.Lambda(lambda x: x[:, -1:, :]),\n",
        "    # Shape => [batch, 1, out_steps*features]\n",
        "    tf.keras.layers.Dense(OUT_STEPS*num_features,\n",
        "                          kernel_initializer=tf.initializers.zeros),\n",
        "    # Shape => [batch, out_steps, features]\n",
        "    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n",
        "])\n",
        "\n",
        "history = compile_and_fit(multi_linear_model, multi_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "multi_val_performance['Linear'] = multi_linear_model.evaluate(multi_window.val)\n",
        "multi_performance['Linear'] = multi_linear_model.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(multi_linear_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUmUE9U0m-mF"
      },
      "source": [
        "multi_dense_model = tf.keras.Sequential([\n",
        "    # Take the last time step.\n",
        "    # Shape [batch, time, features] => [batch, 1, features]\n",
        "    tf.keras.layers.Lambda(lambda x: x[:, -1:, :]),\n",
        "    # Shape => [batch, 1, dense_units]\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    # Shape => [batch, out_steps*features]\n",
        "    tf.keras.layers.Dense(OUT_STEPS*num_features,\n",
        "                          kernel_initializer=tf.initializers.zeros),\n",
        "    # Shape => [batch, out_steps, features]\n",
        "    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n",
        "])\n",
        "\n",
        "history = compile_and_fit(multi_dense_model, multi_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "multi_val_performance['Dense'] = multi_dense_model.evaluate(multi_window.val)\n",
        "multi_performance['Dense'] = multi_dense_model.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(multi_dense_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDATvZX4nC34"
      },
      "source": [
        "##CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ND-rpj-vnEhj"
      },
      "source": [
        "CONV_WIDTH = 3\n",
        "multi_conv_model = tf.keras.Sequential([\n",
        "    # Shape [batch, time, features] => [batch, CONV_WIDTH, features]\n",
        "    tf.keras.layers.Lambda(lambda x: x[:, -CONV_WIDTH:, :]),\n",
        "    # Shape => [batch, 1, conv_units]\n",
        "    tf.keras.layers.Conv1D(128, activation='relu', kernel_size=(CONV_WIDTH)),\n",
        "    # Shape => [batch, 1,  out_steps*features]\n",
        "    tf.keras.layers.Dense(OUT_STEPS*num_features,\n",
        "                          kernel_initializer=tf.initializers.zeros),\n",
        "    # Shape => [batch, out_steps, features]\n",
        "    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n",
        "])\n",
        "\n",
        "history = compile_and_fit(multi_conv_model, multi_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "\n",
        "multi_val_performance['Conv'] = multi_conv_model.evaluate(multi_window.val)\n",
        "multi_performance['Conv'] = multi_conv_model.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(multi_conv_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dw3T4RwwnH25"
      },
      "source": [
        "##RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_irzyxgPnIsC"
      },
      "source": [
        "multi_lstm_model = tf.keras.Sequential([\n",
        "    # Shape [batch, time, features] => [batch, lstm_units]\n",
        "    # Adding more `lstm_units` just overfits more quickly.\n",
        "    tf.keras.layers.LSTM(64, return_sequences=False),\n",
        "    # Shape => [batch, out_steps*features]\n",
        "    tf.keras.layers.Dense(OUT_STEPS*num_features,\n",
        "                          kernel_initializer=tf.initializers.zeros),\n",
        "    # Shape => [batch, out_steps, features]\n",
        "    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n",
        "])\n",
        "\n",
        "history = compile_and_fit(multi_lstm_model, multi_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "\n",
        "multi_val_performance['LSTM'] = multi_lstm_model.evaluate(multi_window.val)\n",
        "multi_performance['LSTM'] = multi_lstm_model.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(multi_lstm_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSL5h7qYnNXu"
      },
      "source": [
        "class FeedBack(tf.keras.Model):\n",
        "  def __init__(self, units, out_steps):\n",
        "    super().__init__()\n",
        "    self.out_steps = out_steps\n",
        "    self.units = units\n",
        "    self.lstm_cell = tf.keras.layers.LSTMCell(units)\n",
        "    # Also wrap the LSTMCell in an RNN to simplify the `warmup` method.\n",
        "    self.lstm_rnn = tf.keras.layers.RNN(self.lstm_cell, return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(num_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW0hidBGnQB7"
      },
      "source": [
        "feedback_model = FeedBack(units=32, out_steps=OUT_STEPS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPEIb3R5nRxH"
      },
      "source": [
        "def warmup(self, inputs):\n",
        "  # inputs.shape => (batch, time, features)\n",
        "  # x.shape => (batch, lstm_units)\n",
        "  x, *state = self.lstm_rnn(inputs)\n",
        "\n",
        "  # predictions.shape => (batch, features)\n",
        "  prediction = self.dense(x)\n",
        "  return prediction, state\n",
        "\n",
        "FeedBack.warmup = warmup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LksQSt8unVNz"
      },
      "source": [
        "prediction, state = feedback_model.warmup(multi_window.example[0])\n",
        "prediction.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2EyymtwnXIR"
      },
      "source": [
        "def call(self, inputs, training=None):\n",
        "  # Use a TensorArray to capture dynamically unrolled outputs.\n",
        "  predictions = []\n",
        "  # Initialize the lstm state\n",
        "  prediction, state = self.warmup(inputs)\n",
        "\n",
        "  # Insert the first prediction\n",
        "  predictions.append(prediction)\n",
        "\n",
        "  # Run the rest of the prediction steps\n",
        "  for n in range(1, self.out_steps):\n",
        "    # Use the last prediction as input.\n",
        "    x = prediction\n",
        "    # Execute one lstm step.\n",
        "    x, state = self.lstm_cell(x, states=state,\n",
        "                              training=training)\n",
        "    # Convert the lstm output to a prediction.\n",
        "    prediction = self.dense(x)\n",
        "    # Add the prediction to the output\n",
        "    predictions.append(prediction)\n",
        "\n",
        "  # predictions.shape => (time, batch, features)\n",
        "  predictions = tf.stack(predictions)\n",
        "  # predictions.shape => (batch, time, features)\n",
        "  predictions = tf.transpose(predictions, [1, 0, 2])\n",
        "  return predictions\n",
        "\n",
        "FeedBack.call = call"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pnp_qfheoNY7"
      },
      "source": [
        "print('Output shape (batch, time, features): ', feedback_model(multi_window.example[0]).shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5aI3c-2ncKk"
      },
      "source": [
        "x = np.arange(len(multi_performance))\n",
        "width = 0.3\n",
        "\n",
        "\n",
        "metric_name = 'root_mean_squared_error'\n",
        "metric_index = lstm_model.metrics_names.index('root_mean_squared_error')\n",
        "val_rmse = [v[metric_index] for v in multi_val_performance.values()]\n",
        "test_rmse = [v[metric_index] for v in multi_performance.values()]\n",
        "\n",
        "plt.bar(x - 0.17, val_rmse, width, label='Validation')\n",
        "plt.bar(x + 0.17, test_rmse, width, label='Test')\n",
        "plt.xticks(ticks=x, labels=multi_performance.keys(),\n",
        "           rotation=45)\n",
        "plt.ylabel(f'RMSE (average over all times and outputs)')\n",
        "_ = plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMqbxMRxnfFg"
      },
      "source": [
        "for name, value in multi_performance.items():\n",
        "  print(f'{name:8s}: {value[1]:0.4f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djMbhMBHnhQ0"
      },
      "source": [
        "**From the visualization and the average RMSE values, Dense and CNN are found to be most competitive ones for prediction.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2UD2z1inj98"
      },
      "source": [
        "## Test using test.csv:\n",
        "Load the test.csv file and as the model is trained on windows, the test.csv would also be split into windows to be used in prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZHnqo69npQr"
      },
      "source": [
        "#load data\n",
        "test_csv_path = '/content/drive/MyDrive/Drug_sales/test_data.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkt3IiPunp-X"
      },
      "source": [
        "df_test = pd.read_csv(test_csv_path)\n",
        "IDs = df_test.pop('id')\n",
        "df_test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmOAyN6nnshV"
      },
      "source": [
        "final_test = df_test/df_test.max()\n",
        "final_test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d62vjEonwPP"
      },
      "source": [
        "w11 = WindowGenerator(input_width=31, label_width=31, shift=1)\n",
        "w11"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPwIZk6KnyCZ"
      },
      "source": [
        "Label column names is None, because we don't have any labels as we need to predict the sales for the test.csv dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fH89idhn0QK"
      },
      "source": [
        "Here I have followed wide-window method for prediction in chunks followed by saving the result in a csv file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ri29pJ4dn3rC"
      },
      "source": [
        "predictions_norm = []\n",
        "wide_window = WindowGenerator(\n",
        "    input_width=4700, label_width=4700, shift=1)\n",
        "for example_inputs1, example_labels1 in wide_window.train.take(1):\n",
        "  predictions_norm.append(abs(dense.predict(example_inputs1)))\n",
        "\n",
        "predictions = np.array(predictions_norm)\n",
        "n= predictions.shape[0]*predictions.shape[1]*predictions.shape[2]*predictions.shape[3]\n",
        "predictions1 = predictions.reshape((n,1))\n",
        "print(predictions1)\n",
        "final_predictions = (predictions1*train_std['sales']) + train_mean['sales'] \n",
        "final_predictions = final_predictions[:len(IDs)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzD3GkSfn6Ws"
      },
      "source": [
        "dict_ofsubmission = {'sales':final_predictions}\n",
        "submission_df = pd.DataFrame(data = final_predictions,index = None, columns = ['sales'])\n",
        "submission_df.to_csv('submission_sales.csv')  #It would contain more than the number of rows. In that case, just select first 0:len(df['id'])\n",
        "submission_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
